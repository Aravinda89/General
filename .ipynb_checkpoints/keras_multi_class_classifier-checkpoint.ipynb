{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version: 1.15.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime as dt\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "#from losses import categorical_focal_loss\n",
    "\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "print(\"TF Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/aravindagayan/Documents/Projects/DataSets/Cat_Dog_data/train'\n",
    "test_dir = '/Users/aravindagayan/Documents/Projects/DataSets/Cat_Dog_data/test'\n",
    "\n",
    "#model_json = \n",
    "#model_weight = \n",
    "\n",
    "MODEL_NAME = 'cats_dogs_classifier'\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "lr=0.001\n",
    "PRETRAINED_MODEL = 'densenet201'\n",
    "CHECKPOINT_PATH = './models'\n",
    "TENSORBOARD_PATH = './tensorboard'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "  <head>\n",
       "  <script type=\"text/javascript\" src=\"http://kozea.github.com/pygal.js/javascripts/svg.jquery.js\"></script>\n",
       "  <script type=\"text/javascript\" src=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"\"></script>\n",
       "  </head>\n",
       "  <body>\n",
       "    <figure>\n",
       "      <?xml version='1.0' encoding='utf-8'?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"chart-9791af48-3fce-4145-881f-fa627d7976fa\" class=\"pygal-chart\" viewBox=\"0 0 800 300\"><!--Generated with pygal 2.4.0 (lxml) Â©Kozea 2012-2016 on 2020-03-15--><!--http://pygal.org--><!--http://github.com/Kozea/pygal--><defs><style type=\"text/css\">#chart-9791af48-3fce-4145-881f-fa627d7976fa{-webkit-user-select:none;-webkit-font-smoothing:antialiased;font-family:Consolas,\"Liberation Mono\",Menlo,Courier,monospace}#chart-9791af48-3fce-4145-881f-fa627d7976fa .title{font-family:Consolas,\"Liberation Mono\",Menlo,Courier,monospace;font-size:16px}#chart-9791af48-3fce-4145-881f-fa627d7976fa .legends .legend text{font-family:Consolas,\"Liberation Mono\",Menlo,Courier,monospace;font-size:14px}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis text{font-family:Consolas,\"Liberation Mono\",Menlo,Courier,monospace;font-size:10px}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis text.major{font-family:Consolas,\"Liberation Mono\",Menlo,Courier,monospace;font-size:10px}#chart-9791af48-3fce-4145-881f-fa627d7976fa .text-overlay text.value{font-family:Consolas,\"Liberation Mono\",Menlo,Courier,monospace;font-size:16px}#chart-9791af48-3fce-4145-881f-fa627d7976fa .text-overlay text.label{font-family:Consolas,\"Liberation Mono\",Menlo,Courier,monospace;font-size:10px}#chart-9791af48-3fce-4145-881f-fa627d7976fa .tooltip{font-family:Consolas,\"Liberation Mono\",Menlo,Courier,monospace;font-size:14px}#chart-9791af48-3fce-4145-881f-fa627d7976fa text.no_data{font-family:Consolas,\"Liberation Mono\",Menlo,Courier,monospace;font-size:64px}\n",
       "#chart-9791af48-3fce-4145-881f-fa627d7976fa{background-color:rgba(249,249,249,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa path,#chart-9791af48-3fce-4145-881f-fa627d7976fa line,#chart-9791af48-3fce-4145-881f-fa627d7976fa rect,#chart-9791af48-3fce-4145-881f-fa627d7976fa circle{-webkit-transition:150ms;-moz-transition:150ms;transition:150ms}#chart-9791af48-3fce-4145-881f-fa627d7976fa .graph &gt; .background{fill:rgba(249,249,249,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .plot &gt; .background{fill:rgba(255,255,255,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .graph{fill:rgba(0,0,0,.87)}#chart-9791af48-3fce-4145-881f-fa627d7976fa text.no_data{fill:rgba(0,0,0,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .title{fill:rgba(0,0,0,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .legends .legend text{fill:rgba(0,0,0,.87)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .legends .legend:hover text{fill:rgba(0,0,0,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis .line{stroke:rgba(0,0,0,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis .guide.line{stroke:rgba(0,0,0,.54)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis .major.line{stroke:rgba(0,0,0,.87)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis text.major{fill:rgba(0,0,0,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.y .guides:hover .guide.line,#chart-9791af48-3fce-4145-881f-fa627d7976fa .line-graph .axis.x .guides:hover .guide.line,#chart-9791af48-3fce-4145-881f-fa627d7976fa .stackedline-graph .axis.x .guides:hover .guide.line,#chart-9791af48-3fce-4145-881f-fa627d7976fa .xy-graph .axis.x .guides:hover .guide.line{stroke:rgba(0,0,0,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis .guides:hover text{fill:rgba(0,0,0,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .reactive{fill-opacity:.7;stroke-opacity:.8}#chart-9791af48-3fce-4145-881f-fa627d7976fa .ci{stroke:rgba(0,0,0,.87)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .reactive.active,#chart-9791af48-3fce-4145-881f-fa627d7976fa .active .reactive{fill-opacity:.8;stroke-opacity:.9;stroke-width:4}#chart-9791af48-3fce-4145-881f-fa627d7976fa .ci .reactive.active{stroke-width:1.5}#chart-9791af48-3fce-4145-881f-fa627d7976fa .series text{fill:rgba(0,0,0,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .tooltip rect{fill:rgba(255,255,255,1);stroke:rgba(0,0,0,1);-webkit-transition:opacity 150ms;-moz-transition:opacity 150ms;transition:opacity 150ms}#chart-9791af48-3fce-4145-881f-fa627d7976fa .tooltip .label{fill:rgba(0,0,0,.87)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .tooltip .label{fill:rgba(0,0,0,.87)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .tooltip .legend{font-size:.8em;fill:rgba(0,0,0,.54)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .tooltip .x_label{font-size:.6em;fill:rgba(0,0,0,1)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .tooltip .xlink{font-size:.5em;text-decoration:underline}#chart-9791af48-3fce-4145-881f-fa627d7976fa .tooltip .value{font-size:1.5em}#chart-9791af48-3fce-4145-881f-fa627d7976fa .bound{font-size:.5em}#chart-9791af48-3fce-4145-881f-fa627d7976fa .max-value{font-size:.75em;fill:rgba(0,0,0,.54)}#chart-9791af48-3fce-4145-881f-fa627d7976fa .map-element{fill:rgba(255,255,255,1);stroke:rgba(0,0,0,.54) !important}#chart-9791af48-3fce-4145-881f-fa627d7976fa .map-element .reactive{fill-opacity:inherit;stroke-opacity:inherit}#chart-9791af48-3fce-4145-881f-fa627d7976fa .color-0,#chart-9791af48-3fce-4145-881f-fa627d7976fa .color-0 a:visited{stroke:#F44336;fill:#F44336}#chart-9791af48-3fce-4145-881f-fa627d7976fa .color-1,#chart-9791af48-3fce-4145-881f-fa627d7976fa .color-1 a:visited{stroke:#3F51B5;fill:#3F51B5}#chart-9791af48-3fce-4145-881f-fa627d7976fa .text-overlay .color-0 text{fill:black}#chart-9791af48-3fce-4145-881f-fa627d7976fa .text-overlay .color-1 text{fill:black}\n",
       "#chart-9791af48-3fce-4145-881f-fa627d7976fa text.no_data{text-anchor:middle}#chart-9791af48-3fce-4145-881f-fa627d7976fa .guide.line{fill:none}#chart-9791af48-3fce-4145-881f-fa627d7976fa .centered{text-anchor:middle}#chart-9791af48-3fce-4145-881f-fa627d7976fa .title{text-anchor:middle}#chart-9791af48-3fce-4145-881f-fa627d7976fa .legends .legend text{fill-opacity:1}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.x text{text-anchor:middle}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.x:not(.web) text[transform]{text-anchor:start}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.x:not(.web) text[transform].backwards{text-anchor:end}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.y text{text-anchor:end}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.y text[transform].backwards{text-anchor:start}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.y2 text{text-anchor:start}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.y2 text[transform].backwards{text-anchor:end}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis .guide.line{stroke-dasharray:4,4}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis .major.guide.line{stroke-dasharray:6,6}#chart-9791af48-3fce-4145-881f-fa627d7976fa .horizontal .axis.y .guide.line,#chart-9791af48-3fce-4145-881f-fa627d7976fa .horizontal .axis.y2 .guide.line,#chart-9791af48-3fce-4145-881f-fa627d7976fa .vertical .axis.x .guide.line{opacity:0}#chart-9791af48-3fce-4145-881f-fa627d7976fa .horizontal .axis.always_show .guide.line,#chart-9791af48-3fce-4145-881f-fa627d7976fa .vertical .axis.always_show .guide.line{opacity:1 !important}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.y .guides:hover .guide.line,#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.y2 .guides:hover .guide.line,#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis.x .guides:hover .guide.line{opacity:1}#chart-9791af48-3fce-4145-881f-fa627d7976fa .axis .guides:hover text{opacity:1}#chart-9791af48-3fce-4145-881f-fa627d7976fa .nofill{fill:none}#chart-9791af48-3fce-4145-881f-fa627d7976fa .subtle-fill{fill-opacity:.2}#chart-9791af48-3fce-4145-881f-fa627d7976fa .dot{stroke-width:1px;fill-opacity:1}#chart-9791af48-3fce-4145-881f-fa627d7976fa .dot.active{stroke-width:5px}#chart-9791af48-3fce-4145-881f-fa627d7976fa .dot.negative{fill:transparent}#chart-9791af48-3fce-4145-881f-fa627d7976fa text,#chart-9791af48-3fce-4145-881f-fa627d7976fa tspan{stroke:none !important}#chart-9791af48-3fce-4145-881f-fa627d7976fa .series text.active{opacity:1}#chart-9791af48-3fce-4145-881f-fa627d7976fa .tooltip rect{fill-opacity:.95;stroke-width:.5}#chart-9791af48-3fce-4145-881f-fa627d7976fa .tooltip text{fill-opacity:1}#chart-9791af48-3fce-4145-881f-fa627d7976fa .showable{visibility:hidden}#chart-9791af48-3fce-4145-881f-fa627d7976fa .showable.shown{visibility:visible}#chart-9791af48-3fce-4145-881f-fa627d7976fa .gauge-background{fill:rgba(229,229,229,1);stroke:none}#chart-9791af48-3fce-4145-881f-fa627d7976fa .bg-lines{stroke:rgba(249,249,249,1);stroke-width:2px}</style><script type=\"text/javascript\">window.pygal = window.pygal || {};window.pygal.config = window.pygal.config || {};window.pygal.config['9791af48-3fce-4145-881f-fa627d7976fa'] = {\"allow_interruptions\": false, \"box_mode\": \"extremes\", \"classes\": [\"pygal-chart\"], \"css\": [\"file://style.css\", \"file://graph.css\"], \"defs\": [], \"disable_xml_declaration\": false, \"dots_size\": 2.5, \"dynamic_print_values\": false, \"explicit_size\": false, \"fill\": false, \"force_uri_protocol\": \"https\", \"formatter\": null, \"half_pie\": false, \"height\": 300, \"include_x_axis\": false, \"inner_radius\": 0, \"interpolate\": null, \"interpolation_parameters\": {}, \"interpolation_precision\": 250, \"inverse_y_axis\": false, \"js\": [\"//kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"], \"legend_at_bottom\": false, \"legend_at_bottom_columns\": null, \"legend_box_size\": 12, \"logarithmic\": false, \"margin\": 20, \"margin_bottom\": null, \"margin_left\": null, \"margin_right\": null, \"margin_top\": null, \"max_scale\": 16, \"min_scale\": 4, \"missing_value_fill_truncation\": \"x\", \"no_data_text\": \"No data\", \"no_prefix\": false, \"order_min\": null, \"pretty_print\": false, \"print_labels\": false, \"print_values\": false, \"print_values_position\": \"center\", \"print_zeroes\": true, \"range\": null, \"rounded_bars\": null, \"secondary_range\": null, \"show_dots\": true, \"show_legend\": true, \"show_minor_x_labels\": true, \"show_minor_y_labels\": true, \"show_only_major_dots\": false, \"show_x_guides\": false, \"show_x_labels\": true, \"show_y_guides\": true, \"show_y_labels\": true, \"spacing\": 10, \"stack_from_top\": false, \"strict\": false, \"stroke\": true, \"stroke_style\": null, \"style\": {\"background\": \"rgba(249, 249, 249, 1)\", \"ci_colors\": [], \"colors\": [\"#F44336\", \"#3F51B5\", \"#009688\", \"#FFC107\", \"#FF5722\", \"#9C27B0\", \"#03A9F4\", \"#8BC34A\", \"#FF9800\", \"#E91E63\", \"#2196F3\", \"#4CAF50\", \"#FFEB3B\", \"#673AB7\", \"#00BCD4\", \"#CDDC39\", \"#9E9E9E\", \"#607D8B\"], \"font_family\": \"Consolas, \\\"Liberation Mono\\\", Menlo, Courier, monospace\", \"foreground\": \"rgba(0, 0, 0, .87)\", \"foreground_strong\": \"rgba(0, 0, 0, 1)\", \"foreground_subtle\": \"rgba(0, 0, 0, .54)\", \"guide_stroke_dasharray\": \"4,4\", \"label_font_family\": \"Consolas, \\\"Liberation Mono\\\", Menlo, Courier, monospace\", \"label_font_size\": 10, \"legend_font_family\": \"Consolas, \\\"Liberation Mono\\\", Menlo, Courier, monospace\", \"legend_font_size\": 14, \"major_guide_stroke_dasharray\": \"6,6\", \"major_label_font_family\": \"Consolas, \\\"Liberation Mono\\\", Menlo, Courier, monospace\", \"major_label_font_size\": 10, \"no_data_font_family\": \"Consolas, \\\"Liberation Mono\\\", Menlo, Courier, monospace\", \"no_data_font_size\": 64, \"opacity\": \".7\", \"opacity_hover\": \".8\", \"plot_background\": \"rgba(255, 255, 255, 1)\", \"stroke_opacity\": \".8\", \"stroke_opacity_hover\": \".9\", \"title_font_family\": \"Consolas, \\\"Liberation Mono\\\", Menlo, Courier, monospace\", \"title_font_size\": 16, \"tooltip_font_family\": \"Consolas, \\\"Liberation Mono\\\", Menlo, Courier, monospace\", \"tooltip_font_size\": 14, \"transition\": \"150ms\", \"value_background\": \"rgba(229, 229, 229, 1)\", \"value_colors\": [], \"value_font_family\": \"Consolas, \\\"Liberation Mono\\\", Menlo, Courier, monospace\", \"value_font_size\": 16, \"value_label_font_family\": \"Consolas, \\\"Liberation Mono\\\", Menlo, Courier, monospace\", \"value_label_font_size\": 10}, \"title\": \"Class Distribution\", \"tooltip_border_radius\": 0, \"tooltip_fancy_mode\": true, \"truncate_label\": null, \"truncate_legend\": null, \"width\": 800, \"x_label_rotation\": 0, \"x_labels\": null, \"x_labels_major\": null, \"x_labels_major_count\": null, \"x_labels_major_every\": null, \"x_title\": null, \"xrange\": null, \"y_label_rotation\": 0, \"y_labels\": null, \"y_labels_major\": null, \"y_labels_major_count\": null, \"y_labels_major_every\": null, \"y_title\": null, \"zero\": 0, \"legends\": [\"cat\", \"dog\"]}</script><script type=\"text/javascript\" xlink:href=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"/></defs><title>Class Distribution</title><g class=\"graph bar-graph vertical\"><rect x=\"0\" y=\"0\" width=\"800\" height=\"300\" class=\"background\"/><g transform=\"translate(101, 46)\" class=\"plot\"><rect x=\"0\" y=\"0\" width=\"678.8\" height=\"234\" class=\"background\"/><g class=\"axis y always_show\"><g class=\"guides\"><path d=\"M0.000000 229.500000 h678.800000\" class=\"axis major line\"/><text x=\"-5\" y=\"233.0\" class=\"major\">0</text><title>0</title></g><g class=\"guides\"><path d=\"M0.000000 204.500000 h678.800000\" class=\"guide line\"/><text x=\"-5\" y=\"208.0\" class=\"\">1000</text><title>1000</title></g><g class=\"guides\"><path d=\"M0.000000 179.500000 h678.800000\" class=\"guide line\"/><text x=\"-5\" y=\"183.0\" class=\"\">2000</text><title>2000</title></g><g class=\"guides\"><path d=\"M0.000000 154.500000 h678.800000\" class=\"guide line\"/><text x=\"-5\" y=\"158.0\" class=\"\">3000</text><title>3000</title></g><g class=\"guides\"><path d=\"M0.000000 129.500000 h678.800000\" class=\"guide line\"/><text x=\"-5\" y=\"133.0\" class=\"\">4000</text><title>4000</title></g><g class=\"guides\"><path d=\"M0.000000 104.500000 h678.800000\" class=\"major guide line\"/><text x=\"-5\" y=\"108.0\" class=\"major\">5000</text><title>5000</title></g><g class=\"guides\"><path d=\"M0.000000 79.500000 h678.800000\" class=\"guide line\"/><text x=\"-5\" y=\"83.0\" class=\"\">6000</text><title>6000</title></g><g class=\"guides\"><path d=\"M0.000000 54.500000 h678.800000\" class=\"guide line\"/><text x=\"-5\" y=\"58.0\" class=\"\">7000</text><title>7000</title></g><g class=\"guides\"><path d=\"M0.000000 29.500000 h678.800000\" class=\"guide line\"/><text x=\"-5\" y=\"33.0\" class=\"\">8000</text><title>8000</title></g><g class=\"guides\"><path d=\"M0.000000 4.500000 h678.800000\" class=\"guide line\"/><text x=\"-5\" y=\"8.0\" class=\"\">9000</text><title>9000</title></g></g><g class=\"series serie-0 color-0\"><g class=\"bars\"><g class=\"bar\"><rect x=\"69.44646153846153\" y=\"4.5\" rx=\"0\" ry=\"0\" width=\"252.72246153846152\" height=\"225.0\" class=\"rect reactive tooltip-trigger\"/><desc class=\"value\">9000</desc><desc class=\"x centered\">195.8076923076923</desc><desc class=\"y centered\">117.0</desc></g></g></g><g class=\"series serie-1 color-1\"><g class=\"bars\"><g class=\"bar\"><rect x=\"356.6310769230769\" y=\"4.5\" rx=\"0\" ry=\"0\" width=\"252.72246153846152\" height=\"225.0\" class=\"rect reactive tooltip-trigger\"/><desc class=\"value\">9000</desc><desc class=\"x centered\">482.99230769230763</desc><desc class=\"y centered\">117.0</desc></g></g></g></g><g class=\"titles\"><text x=\"400.0\" y=\"26\" class=\"title plot_title\">Class Distribution</text></g><g transform=\"translate(101, 46)\" class=\"plot overlay\"><g class=\"series serie-0 color-0\"/><g class=\"series serie-1 color-1\"/></g><g transform=\"translate(101, 46)\" class=\"plot text-overlay\"><g class=\"series serie-0 color-0\"/><g class=\"series serie-1 color-1\"/></g><g transform=\"translate(101, 46)\" class=\"plot tooltip-overlay\"><g transform=\"translate(0 0)\" style=\"opacity: 0\" class=\"tooltip\"><rect rx=\"0\" ry=\"0\" width=\"0\" height=\"0\" class=\"tooltip-box\"/><g class=\"text\"/></g></g><g transform=\"translate(10, 56)\" class=\"legends\"><g id=\"activate-serie-0\" class=\"legend reactive activate-serie\"><rect x=\"0.0\" y=\"1.0\" width=\"12\" height=\"12\" class=\"color-0 reactive\"/><text x=\"17.0\" y=\"11.2\">cat</text></g><g id=\"activate-serie-1\" class=\"legend reactive activate-serie\"><rect x=\"0.0\" y=\"22.0\" width=\"12\" height=\"12\" class=\"color-1 reactive\"/><text x=\"17.0\" y=\"32.2\">dog</text></g></g><g transform=\"translate(790, 56)\" class=\"legends\"/></g></svg>\n",
       "    </figure>\n",
       "  </body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pygal \n",
    "from IPython.display import display, HTML\n",
    "\n",
    "#Create function to display interactive plotting\n",
    "base_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "  <script type=\"text/javascript\" src=\"http://kozea.github.com/pygal.js/javascripts/svg.jquery.js\"></script>\n",
    "  <script type=\"text/javascript\" src=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"\"></script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <figure>\n",
    "      {rendered_chart}\n",
    "    </figure>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def galplot(chart):\n",
    "    rendered_chart = chart.render(is_unicode=True)\n",
    "    plot_html = base_html.format(rendered_chart=rendered_chart)\n",
    "    display(HTML(plot_html))\n",
    "    \n",
    "#Compare class distribution\n",
    "line_chart = pygal.Bar(height=300)\n",
    "line_chart.title = 'Class Distribution'\n",
    "for o in os.listdir(train_dir):\n",
    "    if not o.startswith('.'):\n",
    "        line_chart.add(o, len(os.listdir(os.path.join(train_dir, o))))\n",
    "galplot(line_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(train_dir,'*','*'))\n",
    "img_path = random.choice(file_list)\n",
    "img = load_img(img_path)\n",
    "car_class = img_path.split(\"/\")[-2]\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(car_class, fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for corrupted Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "\n",
    "file_list = [i for i in glob.glob(os.path.join(train_dir,'*','*')) if i.split('/')[-1].split('.')[-1].lower() in ['jpg','png','jpeg']]\n",
    "   \n",
    "for filename in file_list:\n",
    "    try:\n",
    "        img = Image.open(filename) # open the image file\n",
    "        img.verify() # verify that it is, in fact an image\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        print('Bad file: ', filename) # print out the names of corrupt files\n",
    "print('Checked '+ str(len(file_list))+' Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate train, val, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "#Train and Test Set Variables\n",
    "orginal_data_path ='/Users/aravindagayan/Documents/Projects/DataSets/TR'\n",
    "\n",
    "train_val_test_ratio = (.8, .1, .1) #  Data Split\n",
    "test_folder = '/Users/aravindagayan/Documents/Projects/DataSets/Cat_Dog_data/test/'\n",
    "train_folder = '/Users/aravindagayan/Documents/Projects/DataSets/Cat_Dog_data/train/'\n",
    "val_folder = '/Users/aravindagayan/Documents/Projects/DataSets/Cat_Dog_data/val/'\n",
    "\n",
    "file_names = os.listdir(orginal_data_path)\n",
    "file_names = [i for i in file_names if not i.startswith('.')]\n",
    "\n",
    "#Remove Existing Folders if they exist\n",
    "for folder in [test_folder, train_folder, val_folder]:\n",
    "    if os.path.exists(folder) and os.path.isdir(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        \n",
    "#Remake Category Folders in both Train and Test Folders\n",
    "for category in file_names:\n",
    "    os.makedirs(test_folder + category)\n",
    "    os.makedirs(train_folder + category)\n",
    "    os.makedirs(val_folder + category)\n",
    "\n",
    "#Split Data by Train Ratio and copy files to correct directory\n",
    "for idx, category in enumerate(file_names):\n",
    "    file_list = os.listdir(orginal_data_path + '/' + category)\n",
    "    \n",
    "    train_ratio = math.floor(len(file_list) * train_val_test_ratio[0])\n",
    "    val_ratio = math.floor(len(file_list) * train_val_test_ratio[1])\n",
    "    train_list = file_list[:train_ratio]\n",
    "    val_list = file_list[train_ratio:train_ratio + val_ratio]\n",
    "    test_list = file_list[train_ratio + val_ratio:]\n",
    "    \n",
    "    for i, file in enumerate(train_list):\n",
    "        shutil.copy(orginal_data_path + '/' + category + '/' + file, train_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s train images to category folder %s' % (len(train_list), category))  \n",
    "    sys.stdout.write('\\n')\n",
    "    for i, file in enumerate(val_list):\n",
    "        shutil.copy(orginal_data_path + '/' + category + '/' + file, val_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s validation images to category folder %s' % (len(val_list), category))                   \n",
    "    sys.stdout.write('\\n')\n",
    "    for i, file in enumerate(test_list):\n",
    "        shutil.copy(orginal_data_path + '/' + category + '/' + file, test_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s test images to category folder %s' % (len(test_list), category))\n",
    "    sys.stdout.write('\\n')\n",
    "print(\"Done.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16200 images belonging to 2 classes.\n",
      "Found 1800 images belonging to 2 classes.\n",
      "Found 2250 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.1)\n",
    "\n",
    "train_flow = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    subset='training',\n",
    "    shuffle=True)\n",
    "\n",
    "val_flow = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    subset='validation',\n",
    "    shuffle=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_flow = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Train set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'dog']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = [k for k,v in train_flow.class_indices.items()]\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(CLASS_NAMES[label_batch[n].argmax()].title())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(train_flow)\n",
    "show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained = tensorflow.keras.applications.densenet.DenseNet201(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling='max')\n",
    "#pretrained.save('densenet201_pretrained_pool_max.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "densenet201 (Model)          (None, 1920)              18321984  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1967104   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 20,291,138\n",
      "Trainable params: 1,969,154\n",
      "Non-trainable params: 18,321,984\n",
      "_________________________________________________________________\n",
      "Trainable Layers:/n\n",
      "input_1 : False\n",
      "densenet201 : False\n",
      "dense : True\n",
      "dropout : True\n",
      "output : True\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "base_model = tf.keras.models.load_model('./models/pretrained_models/densenet201_pretrained_pool_max.h5')\n",
    "\n",
    "x = Dense(units=1024, activation='relu')(base_model(inputs))\n",
    "x = Dropout(rate=.4)(x)\n",
    "outputs = Dense(2, name='output', activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(lr, epsilon=1e-08)\n",
    "\n",
    "for layer in model.layers[:2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#for layer in model.layers:\n",
    "#    layer.trainable = True\n",
    "    \n",
    "#model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(loss=categorical_focal_loss(alpha=.25, gamma=2), metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "print('Trainable Layers:/n')\n",
    "for layer in model.layers:\n",
    "    print(layer.name, ':', layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model config to JSON\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join('./models', '{}_{}_{}_{dt}.json'.format(MODEL_NAME,\n",
    "                                                                      PRETRAINED_MODEL,\n",
    "                                                                      lr,\n",
    "                                                                      dt=dt.now().strftime(\"%Y-%m-%d--%H-%M\"))), 'w') as json_file:\n",
    "    json.dump(model_json, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model checkpoint\n",
    "model_checkpoint = ModelCheckpoint(filepath=os.path.join(CHECKPOINT_PATH, '{}_{}_{}_Epoch{{epoch:02d}}_{dt}.hdf5'.format(MODEL_NAME,\n",
    "                                                                                                        PRETRAINED_MODEL,\n",
    "                                                                                                        lr,\n",
    "                                                                                                        dt=dt.now().strftime(\"%Y-%m-%d--%H-%M\"))),\n",
    "                                                                                                        monitor='val_loss',\n",
    "                                                                                                        verbose=1, save_best_only=True, save_weights_only=True)\n",
    "# Tensorboard\n",
    "tensorboard = TensorBoard(log_dir=TENSORBOARD_PATH + 'tb_{}_{}_{}_{dt}/'.format(MODEL_NAME, PRETRAINED_MODEL,\n",
    "                                                                                lr,\n",
    "                                                                                dt=dt.now().strftime(\"%Y-%m-%d--%H-%M\")),\n",
    "                                                                                histogram_freq=0,\n",
    "                                                                                write_graph=True,\n",
    "                                                                                write_images=False)\n",
    "\n",
    "# Logger\n",
    "csv_logger = CSVLogger(TENSORBOARD_PATH + 'TrainLog_{}_{}_{}_{dt}.csv'.format(MODEL_NAME,\n",
    "                                                                                PRETRAINED_MODEL,\n",
    "                                                                                lr,\n",
    "                                                                                dt=dt.now().strftime(\"%Y-%m-%d--%H-%M\"),\n",
    "                                                                                separator=';',\n",
    "                                                                                append=True))\n",
    "# Callbacks\n",
    "callbacks_list = [model_checkpoint, tensorboard, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  249/16200 [..............................] - ETA: 1:51:43 - loss: 9.0895 - acc: 0.5181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-f8f88075c5dc>\", line 7, in <module>\n",
      "    callbacks=callbacks_list)\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 727, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 603, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 265, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1017, in train_on_batch\n",
      "    outputs = self.train_function(ins)  # pylint: disable=not-callable\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/__init__.py\", line 43, in <module>\n",
      "    from tensorflow.contrib import cudnn_rnn\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/__init__.py\", line 38, in <module>\n",
      "    from tensorflow.contrib.cudnn_rnn.python.layers import *\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/__init__.py\", line 38, in <module>\n",
      "    from tensorflow.contrib.cudnn_rnn.python.layers import *\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/layers/__init__.py\", line 23, in <module>\n",
      "    from tensorflow.contrib.cudnn_rnn.python.layers.cudnn_rnn import *\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/layers/cudnn_rnn.py\", line 20, in <module>\n",
      "    from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 22, in <module>\n",
      "    from tensorflow.contrib.rnn.python.ops import lstm_ops\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/rnn/__init__.py\", line 93, in <module>\n",
      "    from tensorflow.contrib.rnn.python.ops.rnn_cell import *\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/rnn/python/ops/rnn_cell.py\", line 24, in <module>\n",
      "    from tensorflow.contrib.layers.python.layers import layers\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/layers/__init__.py\", line 116, in <module>\n",
      "    from tensorflow.contrib.layers.python.layers import *\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/__init__.py\", line 33, in <module>\n",
      "    from tensorflow.contrib.layers.python.layers.target_column import *\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/target_column.py\", line 24, in <module>\n",
      "    from tensorflow.contrib.losses.python.losses import loss_ops\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/losses/__init__.py\", line 25, in <module>\n",
      "    from tensorflow.contrib.losses.python import metric_learning\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/losses/python/metric_learning/__init__.py\", line 25, in <module>\n",
      "    from tensorflow.contrib.losses.python.metric_learning.metric_loss_ops import *\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/tensorflow_core/contrib/losses/python/metric_learning/metric_loss_ops.py\", line 34, in <module>\n",
      "    from sklearn import metrics\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/sklearn/metrics/__init__.py\", line 7, in <module>\n",
      "    from .ranking import auc\n",
      "  File \"/Users/aravindagayan/anaconda3/envs/TF2/lib/python3.7/site-packages/sklearn/metrics/ranking.py\", line 31, in <module>\n",
      "    from ..utils.multiclass import type_of_target\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 963, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 906, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1280, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1249, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1211, in _path_importer_cache\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model.fit(train_flow,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=val_flow,\n",
    "          validation_steps=math.ceil(val_flow.samples / val_flow.batch_size),\n",
    "          steps_per_epoch=math.ceil(train_flow.samples / train_flow.batch_size),\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_json, 'r') as f:\n",
    "    model = tf.keras.models.model_from_json(json.loads(f.read()))\n",
    "model.load_weights(model_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(test_dir,'*',\"*\"))\n",
    "img_path = random.choice(file_list)\n",
    "img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "print(\"Image Name: \", img_path)\n",
    "img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(img_cat, fontsize=16)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print(\"Predictions: \", preds)\n",
    "print(preds[0].argmax())\n",
    "test_flow.class_indices\n",
    "\n",
    "label = [k for k,v in test_flow.class_indices.items()]\n",
    "top_x = 3\n",
    "top_args = preds[0].argsort()[-top_x:][::-1]\n",
    "preds_label = [label[p] for p in top_args]\n",
    "print(\"\\nTop \" + str(top_x) + \" confidence: \" + \" \".join(map(str, sorted(preds[0])[-top_x:][::-1])))\n",
    "print(\"Top \" + str(top_x) + \" labels: \" + \" \".join(map(str, preds_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flow.reset()\n",
    "loss, acc, top_5 = model.evaluate_generator(\n",
    "    test_flow,\n",
    "    verbose = True,\n",
    "    steps=math.ceil(test_flow.samples/test_flow.batch_size))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Acc: \", acc)\n",
    "print(\"Top 5: \", top_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
