{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime as dt\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "#from losses import categorical_focal_loss\n",
    "\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "print(\"TF Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/aravindagayan/Documents/Projects/DataSets/Cat_Dog_data/train'\n",
    "test_dir = '/Users/aravindagayan/Documents/Projects/DataSets/Cat_Dog_data/test'\n",
    "\n",
    "#model_json = \n",
    "#model_weight = \n",
    "\n",
    "MODEL_NAME = 'cats_dogs_classifier'\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "lr=0.001\n",
    "PRETRAINED_MODEL = 'densenet201'\n",
    "CHECKPOINT_PATH = './models'\n",
    "TENSORBOARD_PATH = './tensorboard'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygal \n",
    "from IPython.display import display, HTML\n",
    "\n",
    "#Create function to display interactive plotting\n",
    "base_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "  <script type=\"text/javascript\" src=\"http://kozea.github.com/pygal.js/javascripts/svg.jquery.js\"></script>\n",
    "  <script type=\"text/javascript\" src=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"\"></script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <figure>\n",
    "      {rendered_chart}\n",
    "    </figure>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "def galplot(chart):\n",
    "    rendered_chart = chart.render(is_unicode=True)\n",
    "    plot_html = base_html.format(rendered_chart=rendered_chart)\n",
    "    display(HTML(plot_html))\n",
    "    \n",
    "#Compare class distribution\n",
    "line_chart = pygal.Bar(height=300)\n",
    "line_chart.title = 'Class Distribution'\n",
    "for o in os.listdir(train_dir):\n",
    "    if not o.startswith('.'):\n",
    "        line_chart.add(o, len(os.listdir(os.path.join(train_dir, o))))\n",
    "galplot(line_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(train_dir,'*','*'))\n",
    "img_path = random.choice(file_list)\n",
    "img = load_img(img_path)\n",
    "car_class = img_path.split(\"/\")[-2]\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(car_class, fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for corrupted Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image\n",
    "\n",
    "file_list = [i for i in glob.glob(os.path.join(train_dir,'*','*')) if i.split('/')[-1].split('.')[-1].lower() in ['jpg','png','jpeg']]\n",
    "   \n",
    "for filename in file_list:\n",
    "    try:\n",
    "        img = Image.open(filename) # open the image file\n",
    "        img.verify() # verify that it is, in fact an image\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        print('Bad file: ', filename) # print out the names of corrupt files\n",
    "print('Checked '+ str(len(file_list))+' Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate train, val, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "#Train and Test Set Variables\n",
    "orginal_data_path ='/Users/aravindagayan/Documents/Projects/DataSets/TR'\n",
    "\n",
    "train_val_test_ratio = (.8, .1, .1) #  Data Split\n",
    "test_folder = '/Users/aravindagayan/Documents/Projects/DataSets/Cat_Dog_data/test/'\n",
    "train_folder = '/Users/aravindagayan/Documents/Projects/DataSets/Cat_Dog_data/train/'\n",
    "val_folder = '/Users/aravindagayan/Documents/Projects/DataSets/Cat_Dog_data/val/'\n",
    "\n",
    "file_names = os.listdir(orginal_data_path)\n",
    "file_names = [i for i in file_names if not i.startswith('.')]\n",
    "\n",
    "#Remove Existing Folders if they exist\n",
    "for folder in [test_folder, train_folder, val_folder]:\n",
    "    if os.path.exists(folder) and os.path.isdir(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        \n",
    "#Remake Category Folders in both Train and Test Folders\n",
    "for category in file_names:\n",
    "    os.makedirs(test_folder + category)\n",
    "    os.makedirs(train_folder + category)\n",
    "    os.makedirs(val_folder + category)\n",
    "\n",
    "#Split Data by Train Ratio and copy files to correct directory\n",
    "for idx, category in enumerate(file_names):\n",
    "    file_list = os.listdir(orginal_data_path + '/' + category)\n",
    "    \n",
    "    train_ratio = math.floor(len(file_list) * train_val_test_ratio[0])\n",
    "    val_ratio = math.floor(len(file_list) * train_val_test_ratio[1])\n",
    "    train_list = file_list[:train_ratio]\n",
    "    val_list = file_list[train_ratio:train_ratio + val_ratio]\n",
    "    test_list = file_list[train_ratio + val_ratio:]\n",
    "    \n",
    "    for i, file in enumerate(train_list):\n",
    "        shutil.copy(orginal_data_path + '/' + category + '/' + file, train_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s train images to category folder %s' % (len(train_list), category))  \n",
    "    sys.stdout.write('\\n')\n",
    "    for i, file in enumerate(val_list):\n",
    "        shutil.copy(orginal_data_path + '/' + category + '/' + file, val_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s validation images to category folder %s' % (len(val_list), category))                   \n",
    "    sys.stdout.write('\\n')\n",
    "    for i, file in enumerate(test_list):\n",
    "        shutil.copy(orginal_data_path + '/' + category + '/' + file, test_folder + '/' + category + '/' + file)\n",
    "    sys.stdout.write('Moving %s test images to category folder %s' % (len(test_list), category))\n",
    "    sys.stdout.write('\\n')\n",
    "print(\"Done.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.1)\n",
    "\n",
    "train_flow = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    subset='training',\n",
    "    shuffle=True)\n",
    "\n",
    "val_flow = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    subset='validation',\n",
    "    shuffle=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_flow = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Train set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [k for k,v in train_flow.class_indices.items()]\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(CLASS_NAMES[label_batch[n].argmax()].title())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(train_flow)\n",
    "show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained = tensorflow.keras.applications.densenet.DenseNet201(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling='max')\n",
    "#pretrained.save('densenet201_pretrained_pool_max.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "base_model = tf.keras.models.load_model('./models/pretrained_models/densenet201_pretrained_pool_max.h5')\n",
    "\n",
    "x = Dense(units=1024, activation='relu')(base_model(inputs))\n",
    "x = Dropout(rate=.4)(x)\n",
    "outputs = Dense(2, name='output', activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(lr, epsilon=1e-08)\n",
    "\n",
    "for layer in model.layers[:2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#for layer in model.layers:\n",
    "#    layer.trainable = True\n",
    "    \n",
    "#model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(loss=categorical_focal_loss(alpha=.25, gamma=2), metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "print('Trainable Layers:/n')\n",
    "for layer in model.layers:\n",
    "    print(layer.name, ':', layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model config to JSON\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join('./models', '{}_{}_{}_{dt}.json'.format(MODEL_NAME,\n",
    "                                                                      PRETRAINED_MODEL,\n",
    "                                                                      lr,\n",
    "                                                                      dt=dt.now().strftime(\"%Y-%m-%d--%H-%M\"))), 'w') as json_file:\n",
    "    json.dump(model_json, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model checkpoint\n",
    "model_checkpoint = ModelCheckpoint(filepath=os.path.join(CHECKPOINT_PATH, '{}_{}_{}_Epoch{{epoch:02d}}_{dt}.hdf5'.format(MODEL_NAME,\n",
    "                                                                                                        PRETRAINED_MODEL,\n",
    "                                                                                                        lr,\n",
    "                                                                                                        dt=dt.now().strftime(\"%Y-%m-%d--%H-%M\"))),\n",
    "                                                                                                        monitor='val_loss',\n",
    "                                                                                                        verbose=1, save_best_only=True, save_weights_only=True)\n",
    "# Tensorboard\n",
    "tensorboard = TensorBoard(log_dir=TENSORBOARD_PATH + 'tb_{}_{}_{}_{dt}/'.format(MODEL_NAME, PRETRAINED_MODEL,\n",
    "                                                                                lr,\n",
    "                                                                                dt=dt.now().strftime(\"%Y-%m-%d--%H-%M\")),\n",
    "                                                                                histogram_freq=0,\n",
    "                                                                                write_graph=True,\n",
    "                                                                                write_images=False)\n",
    "\n",
    "# Logger\n",
    "csv_logger = CSVLogger(TENSORBOARD_PATH + 'TrainLog_{}_{}_{}_{dt}.csv'.format(MODEL_NAME,\n",
    "                                                                                PRETRAINED_MODEL,\n",
    "                                                                                lr,\n",
    "                                                                                dt=dt.now().strftime(\"%Y-%m-%d--%H-%M\"),\n",
    "                                                                                separator=';',\n",
    "                                                                                append=True))\n",
    "# Callbacks\n",
    "callbacks_list = [model_checkpoint, tensorboard, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_flow,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=val_flow,\n",
    "          validation_steps=math.ceil(val_flow.samples / val_flow.batch_size),\n",
    "          steps_per_epoch=math.ceil(train_flow.samples / train_flow.batch_size),\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_json, 'r') as f:\n",
    "    model = tf.keras.models.model_from_json(json.loads(f.read()))\n",
    "model.load_weights(model_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(test_dir,'*',\"*\"))\n",
    "img_path = random.choice(file_list)\n",
    "img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "print(\"Image Name: \", img_path)\n",
    "img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(img_cat, fontsize=16)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print(\"Predictions: \", preds)\n",
    "print(preds[0].argmax())\n",
    "test_flow.class_indices\n",
    "\n",
    "label = [k for k,v in test_flow.class_indices.items()]\n",
    "top_x = 3\n",
    "top_args = preds[0].argsort()[-top_x:][::-1]\n",
    "preds_label = [label[p] for p in top_args]\n",
    "print(\"\\nTop \" + str(top_x) + \" confidence: \" + \" \".join(map(str, sorted(preds[0])[-top_x:][::-1])))\n",
    "print(\"Top \" + str(top_x) + \" labels: \" + \" \".join(map(str, preds_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
